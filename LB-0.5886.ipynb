{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKavJMuwJu7i",
    "outputId": "222bf974-c158-4fde-f381-7e5e696f2030"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import reduce\n",
    "import os.path as osp\n",
    "import ast\n",
    "import math\n",
    "from scipy import stats\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import coo_matrix\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as ctb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Meg3SKu_Vm7A"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrI-CjZtLVbM",
    "outputId": "2bb81b3b-09f3-44a2-dd3c-65a4cc37cbef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package stopwords to /home/alexch/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/alexch/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "from scipy.sparse import hstack\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uec56EL3LFTh"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "valid_df = pd.read_csv(\"../input/valid.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "trainval_df = train_df.append(valid_df, ignore_index=True)\n",
    "sample_df = pd.read_csv('../input/submission_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_context = 0\n",
    "for i, row in train_df.append(valid_df, ignore_index=True).append(test_df, ignore_index=True).iterrows():\n",
    "    if len(ast.literal_eval(row['stance_label'])) > max_context:\n",
    "        max_context = len(ast.literal_eval(row['stance_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stance_encoder = {'OPPOSE': -1, 'NULL': 0, 'SUPPORT': 1}\n",
    "stance_decoder = {-1: 'OPPOSE', 0: 'NULL', 1: 'SUPPORT'}\n",
    "impact_encoder = {'UNKNOWN': -1, 'NOT_IMPACTFUL': 0, 'MEDIUM_IMPACT': 1, 'IMPACTFUL': 2}\n",
    "impact_decoder = {-1: 'UNKNOWN', 0: 'NOT_IMPACTFUL', 1: 'MEDIUM_IMPACT', 2: 'IMPACTFUL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_eng(text, stance):\n",
    "    stance[0] = 'SUPPORT'\n",
    "    stance_embedded = []\n",
    "    for i, sentence in enumerate(text):\n",
    "        word_embedded = []\n",
    "        for word in sentence.split(' '):\n",
    "            word_embedded.append(word + stance[i])\n",
    "            \n",
    "        stance_embedded.append(' '.join(word_embedded))\n",
    "    return stance_embedded\n",
    "\n",
    "def seperate_data(df):\n",
    "    index = []\n",
    "    text = []\n",
    "    feats = []\n",
    "    stance_label = []\n",
    "    to_topic_stance_label = []\n",
    "    impact_label = []\n",
    "    for i, row in df.iterrows():\n",
    "        index.append(row['id'])\n",
    "        example_text = [row['text']] + ast.literal_eval(row['context'])     \n",
    "        stance_str = ['SUPPORT'] + ast.literal_eval(row['stance_label'])[1:]\n",
    "        to_topic_stance_str = ['SUPPORT', stance_str[1]]\n",
    "        for i in range(2, len(stance_str)):\n",
    "            if stance_str[i] == 'SUPPORT':\n",
    "                to_topic_stance_str.append(to_topic_stance_str[-1])\n",
    "            else:\n",
    "                to_topic_stance_str.append(\n",
    "                    stance_decoder[stance_encoder[to_topic_stance_str[-1]] * -1])\n",
    "                \n",
    "        feat = feature_eng(example_text, stance_str)\n",
    "        \n",
    "        text.append(example_text)\n",
    "        feats.append(feat)\n",
    "        stance_label.append(' '.join(stance_str))\n",
    "        to_topic_stance_label.append(' '.join(to_topic_stance_str))\n",
    "        impact_label.append(impact_encoder[row['impact_label']])\n",
    "    \n",
    "    text = [\" \".join(sentence) for sentence in text]\n",
    "    return np.array(index), np.array(text), np.array(to_topic_stance_label), np.array(impact_label)\n",
    "\n",
    "def context_length_feat(df, max_context=24):\n",
    "    length_feat = np.zeros((len(df), max_context))\n",
    "    for i, row in df.iterrows():\n",
    "        context = ast.literal_eval(row['context'])\n",
    "        for j, text in enumerate(context):\n",
    "            length_feat[i][j] = len(text.split(' '))\n",
    "    \n",
    "    return length_feat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iFssvBvwLLSH"
   },
   "outputs": [],
   "source": [
    "train_ids, train_texts, train_stance, train_labels = seperate_data(train_df)\n",
    "valid_ids, valid_texts, valid_stance, valid_labels = seperate_data(valid_df)\n",
    "trainval_ids, trainval_texts, trainval_stance, trainval_labels = seperate_data(trainval_df)\n",
    "test_ids, test_texts, test_stance, test_labels = seperate_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PULuW2kQL0e_"
   },
   "outputs": [],
   "source": [
    "train_text_length = context_length_feat(train_df, max_context=max_context)\n",
    "valid_text_length = context_length_feat(valid_df, max_context=max_context)\n",
    "trainval_text_length = context_length_feat(trainval_df, max_context=max_context)\n",
    "test_text_length = context_length_feat(test_df, max_context=max_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7K1fwJYRwaG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wHsadZnvcDM8"
   },
   "outputs": [],
   "source": [
    "class_names = train_df.impact_label.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JTXMtM7KSy2D"
   },
   "outputs": [],
   "source": [
    "text_count_vect = CountVectorizer(lowercase=True, stop_words=\"english\", ngram_range=(1, 4), min_df=0.006)\n",
    "stance_count_vect = CountVectorizer(lowercase=True, ngram_range=(1, 8))\n",
    "\n",
    "X_train = text_count_vect.fit_transform(train_texts)\n",
    "X_valid = text_count_vect.transform(valid_texts)\n",
    "# X_trainval = text_count_vect.transform(trainval_texts)\n",
    "X_test = text_count_vect.transform(test_texts)\n",
    "\n",
    "train_stance_vec = stance_count_vect.fit_transform(train_stance)\n",
    "valid_stance_vec = stance_count_vect.transform(valid_stance)\n",
    "# trainval_stance_vec = stance_count_vect.transform(trainval_stance)\n",
    "test_stance_vec = stance_count_vect.transform(test_stance)\n",
    "\n",
    "X_train = hstack((X_train, train_stance_vec))\n",
    "X_valid = hstack((X_valid, valid_stance_vec))\n",
    "# X_trainval = hstack((X_trainval, trainval_stance_vec))\n",
    "X_test = hstack((X_test, test_stance_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5170, 3125)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0iBfVlWuNjCO",
    "outputId": "b3002fec-f785-40fe-c99c-ad51afba2c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF F-1 score: 0.5949173273462418 Counter({2: 755, 1: 191, 0: 162})\n",
      "RF F-1 score: 0.5928309967276545 Counter({2: 748, 1: 197, 0: 163})\n",
      "RF F-1 score: 0.6140307516113676 Counter({2: 747, 1: 200, 0: 161})\n",
      "RF F-1 score: 0.6029671976315153 Counter({2: 741, 1: 199, 0: 168})\n",
      "RF F-1 score: 0.6168451717364761 Counter({2: 739, 1: 201, 0: 168})\n"
     ]
    }
   ],
   "source": [
    "# single model\n",
    "best_f1 = 0\n",
    "for seed in range(10000, 10005):\n",
    "    model = RandomForestClassifier(n_estimators=80, random_state=20210402 + seed)\n",
    "    model.fit(X_train, train_labels)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "    f1_score = metrics.f1_score(valid_labels, valid_pred, average='macro')\n",
    "    print(\"RF F-1 score:\", f1_score, Counter(valid_pred))\n",
    "    test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_count_vect = CountVectorizer(lowercase=True, stop_words=\"english\", ngram_range=(1, 4), min_df=0.008)\n",
    "stance_count_vect = CountVectorizer(lowercase=True, ngram_range=(1, 8))\n",
    "\n",
    "trainval_stance_vec = stance_count_vect.fit_transform(trainval_stance)\n",
    "test_stance_vec = stance_count_vect.transform(test_stance)\n",
    "\n",
    "X_trainval = text_count_vect.fit_transform(trainval_texts)\n",
    "X_test = text_count_vect.transform(test_texts)\n",
    "\n",
    "X_trainval = hstack((X_trainval, trainval_stance_vec))\n",
    "X_test = hstack((X_test, test_stance_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 749, 1: 195, 0: 164})\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=80, random_state=12345679)\n",
    "model.fit(X_trainval, trainval_labels)\n",
    "test_pred = model.predict(X_test)\n",
    "sample_df['pred'] = test_pred\n",
    "print(Counter(test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 749, 1: 195, 0: 164})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.to_csv('rfc.csv', index=False)\n",
    "submission_df = pd.read_csv('rfc.csv')\n",
    "Counter(submission_df['pred'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qARjFJrrHxp",
    "outputId": "561a90cc-4cff-43f7-c66a-91405ca88e65"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_kfolds(kfolds_pred):\n",
    "    m = stats.mode(fkold_test_pred, axis=0)[0][0]\n",
    "    ensembled = m\n",
    "    for i, ps in enumerate(kfolds_pred.T):\n",
    "        if len(ps[ps == m[i]]) <= 2:\n",
    "            if 0 in ps and 2 in ps:\n",
    "                print(ps)\n",
    "                ensembled[i] = 1\n",
    "            \n",
    "    return ensembled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tUFCyzG5JJ9g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "RF F-1 score: 0.5974081944719485\n",
      "fold 1\n",
      "RF F-1 score: 0.606731746867934\n",
      "fold 2\n",
      "RF F-1 score: 0.5769031216150579\n",
      "fold 3\n",
      "RF F-1 score: 0.5900896544312236\n",
      "fold 4\n",
      "RF F-1 score: 0.6041251480821814\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fkold_test_pred = []\n",
    "skf = StratifiedKFold(n_splits=5, random_state=20210402, shuffle=True)\n",
    "for i, (train_index, valid_index) in enumerate(skf.split(trainval_texts, trainval_labels)):\n",
    "    train_texts = trainval_texts[train_index]\n",
    "    train_stance = trainval_stance[train_index]\n",
    "    train_labels = trainval_labels[train_index]\n",
    "\n",
    "    valid_texts = trainval_texts[valid_index]\n",
    "    valid_stance = trainval_stance[valid_index]\n",
    "    valid_labels = trainval_labels[valid_index]\n",
    "\n",
    "    text_count_vect = CountVectorizer(lowercase=True, stop_words=\"english\", ngram_range=(1, 4), min_df=0.006)\n",
    "    stance_count_vect = CountVectorizer(lowercase=True, ngram_range=(1, 8))\n",
    "    \n",
    "    train_stance_vec = stance_count_vect.fit_transform(train_stance)\n",
    "    valid_stance_vec = stance_count_vect.transform(valid_stance)\n",
    "    test_stance_vec = stance_count_vect.transform(test_stance)\n",
    "    \n",
    "    X_train = text_count_vect.fit_transform(train_texts)\n",
    "    X_valid = text_count_vect.transform(valid_texts)\n",
    "    X_test = text_count_vect.transform(test_texts)\n",
    "\n",
    "    X_train = hstack((X_train, train_stance_vec))\n",
    "    X_valid = hstack((X_valid, valid_stance_vec))\n",
    "    X_test = hstack((X_test, test_stance_vec))\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=70, random_state=20210402 + i)\n",
    "    model.fit(X_train, train_labels)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "    print(\"fold\", i)\n",
    "    print(f\"RF F-1 score: {metrics.f1_score(valid_labels, valid_pred, average='macro')}\")\n",
    "    \n",
    "    test_pred = model.predict(X_test)\n",
    "    fkold_test_pred.append(test_pred)\n",
    "\n",
    "fkold_test_pred = np.array(fkold_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 2 0]\n",
      "[2 0 1 2 0]\n",
      "[1 2 2 0 1]\n",
      "[1 1 2 0 0]\n",
      "[2 1 2 0 0]\n",
      "[1 2 1 0 2]\n",
      "Counter({2: 748, 1: 195, 0: 165})\n"
     ]
    }
   ],
   "source": [
    "test_pred = ensemble_kfolds(fkold_test_pred)\n",
    "print(Counter(test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "n9t9mDHZb9fa"
   },
   "outputs": [],
   "source": [
    "sample_df['pred'] = test_pred\n",
    "sample_df.to_csv('rfc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
