{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKavJMuwJu7i",
    "outputId": "222bf974-c158-4fde-f381-7e5e696f2030"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import reduce\n",
    "import os.path as osp\n",
    "import ast\n",
    "import math\n",
    "from scipy import stats\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import coo_matrix\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as ctb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Meg3SKu_Vm7A"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrI-CjZtLVbM",
    "outputId": "2bb81b3b-09f3-44a2-dd3c-65a4cc37cbef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package stopwords to /home/alexch/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/alexch/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "from scipy.sparse import hstack\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uec56EL3LFTh"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "valid_df = pd.read_csv(\"../input/valid.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "trainval_df = train_df.append(valid_df, ignore_index=True)\n",
    "sample_df = pd.read_csv('../input/submission_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stance_encoder = {'OPPOSE': -1, 'NULL': 0, 'SUPPORT': 1}\n",
    "stance_decoder = {-1: 'OPPOSE', 0: 'NULL', 1: 'SUPPORT'}\n",
    "impact_encoder = {'UNKNOWN': -1, 'NOT_IMPACTFUL': 0, 'MEDIUM_IMPACT': 1, 'IMPACTFUL': 2}\n",
    "impact_decoder = {-1: 'UNKNOWN', 0: 'NOT_IMPACTFUL', 1: 'MEDIUM_IMPACT', 2: 'IMPACTFUL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_data(df):\n",
    "    index = []\n",
    "    text = []\n",
    "    feats = []\n",
    "    stance_label = []\n",
    "    to_topic_stance_label = []\n",
    "    impact_label = []\n",
    "    for i, row in df.iterrows():\n",
    "        index.append(row['id'])\n",
    "        example_text = [row['text']] + ast.literal_eval(row['context'])\n",
    "        stance_str = ['SUPPORT'] + ast.literal_eval(row['stance_label'])[1:]\n",
    "        to_topic_stance_str = ['SUPPORT', stance_str[1]]\n",
    "        for i in range(2, len(stance_str)):\n",
    "            if stance_str[i] == 'SUPPORT':\n",
    "                to_topic_stance_str.append(to_topic_stance_str[-1])\n",
    "            else:\n",
    "                to_topic_stance_str.append(\n",
    "                    stance_decoder[stance_encoder[to_topic_stance_str[-1]] * -1])\n",
    "                        \n",
    "        text.append(example_text)\n",
    "        stance_label.append(' '.join(stance_str))\n",
    "        to_topic_stance_label.append(' '.join(to_topic_stance_str))\n",
    "        impact_label.append(impact_encoder[row['impact_label']])\n",
    "    \n",
    "    text = [\" \".join(sentence) for sentence in text]\n",
    "    return np.array(index), np.array(text), np.array(to_topic_stance_label), np.array(impact_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iFssvBvwLLSH"
   },
   "outputs": [],
   "source": [
    "train_ids, train_texts, train_stance, train_labels = seperate_data(train_df)\n",
    "valid_ids, valid_texts, valid_stance, valid_labels = seperate_data(valid_df)\n",
    "trainval_ids, trainval_texts, trainval_stance, trainval_labels = seperate_data(trainval_df)\n",
    "test_ids, test_texts, test_stance, test_labels = seperate_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7K1fwJYRwaG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_kfolds(kfolds_pred):\n",
    "    m = stats.mode(fkold_test_pred, axis=0)[0][0]\n",
    "    ensembled = m\n",
    "    for i, ps in enumerate(kfolds_pred.T):\n",
    "        if len(ps[ps == m[i]]) <= 2:\n",
    "            if 0 in ps and 2 in ps:\n",
    "                print(ps)\n",
    "                ensembled[i] = 1\n",
    "            \n",
    "    return ensembled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tUFCyzG5JJ9g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "RF F-1 score: 0.5974081944719485\n",
      "fold 1\n",
      "RF F-1 score: 0.606731746867934\n",
      "fold 2\n",
      "RF F-1 score: 0.5769031216150579\n",
      "fold 3\n",
      "RF F-1 score: 0.5900896544312236\n",
      "fold 4\n",
      "RF F-1 score: 0.6041251480821814\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fkold_test_pred = []\n",
    "skf = StratifiedKFold(n_splits=5, random_state=20210402, shuffle=True)\n",
    "for i, (train_index, valid_index) in enumerate(skf.split(trainval_texts, trainval_labels)):\n",
    "    train_texts = trainval_texts[train_index]\n",
    "    train_stance = trainval_stance[train_index]\n",
    "    train_labels = trainval_labels[train_index]\n",
    "\n",
    "    valid_texts = trainval_texts[valid_index]\n",
    "    valid_stance = trainval_stance[valid_index]\n",
    "    valid_labels = trainval_labels[valid_index]\n",
    "\n",
    "    text_count_vect = CountVectorizer(lowercase=True, stop_words=\"english\", ngram_range=(1, 4), min_df=0.006)\n",
    "    stance_count_vect = CountVectorizer(lowercase=True, ngram_range=(1, 8))\n",
    "    \n",
    "    train_stance_vec = stance_count_vect.fit_transform(train_stance)\n",
    "    valid_stance_vec = stance_count_vect.transform(valid_stance)\n",
    "    test_stance_vec = stance_count_vect.transform(test_stance)\n",
    "    \n",
    "    X_train = text_count_vect.fit_transform(train_texts)\n",
    "    X_valid = text_count_vect.transform(valid_texts)\n",
    "    X_test = text_count_vect.transform(test_texts)\n",
    "\n",
    "    X_train = hstack((X_train, train_stance_vec))\n",
    "    X_valid = hstack((X_valid, valid_stance_vec))\n",
    "    X_test = hstack((X_test, test_stance_vec))\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=70, random_state=20210402 + i)\n",
    "    model.fit(X_train, train_labels)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "    print(\"fold\", i)\n",
    "    print(f\"RF F-1 score: {metrics.f1_score(valid_labels, valid_pred, average='macro')}\")\n",
    "    \n",
    "    test_pred = model.predict(X_test)\n",
    "    fkold_test_pred.append(test_pred)\n",
    "\n",
    "fkold_test_pred = np.array(fkold_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 2 0]\n",
      "[2 0 1 2 0]\n",
      "[1 2 2 0 1]\n",
      "[1 1 2 0 0]\n",
      "[2 1 2 0 0]\n",
      "[1 2 1 0 2]\n",
      "Counter({2: 748, 1: 195, 0: 165})\n"
     ]
    }
   ],
   "source": [
    "test_pred = ensemble_kfolds(fkold_test_pred)\n",
    "print(Counter(test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "n9t9mDHZb9fa"
   },
   "outputs": [],
   "source": [
    "sample_df['pred'] = test_pred\n",
    "sample_df.to_csv('rfc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
