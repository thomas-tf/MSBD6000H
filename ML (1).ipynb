{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKavJMuwJu7i",
        "outputId": "69edabd9-90c6-4e25-d956-5cc7415de6e3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrI-CjZtLVbM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b7512cc-98c9-440c-e758-0d424adc5116"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from gensim.models import Word2Vec\n",
        "from nltk import word_tokenize\n",
        "from scipy.sparse import hstack\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uec56EL3LFTh"
      },
      "source": [
        "df_train = pd.read_csv(\"drive/My Drive/UST/6000H/ml4nlp-argimpact/train.csv\")\n",
        "df_test = pd.read_csv(\"drive/My Drive/UST/6000H/ml4nlp-argimpact/test.csv\")\n",
        "df_valid = pd.read_csv(\"drive/My Drive/UST/6000H/ml4nlp-argimpact/valid.csv\")"
      ],
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFssvBvwLLSH"
      },
      "source": [
        "df_train = df_train.append(df_valid)"
      ],
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PULuW2kQL0e_"
      },
      "source": [
        "class_names = df_train.impact_label.unique().tolist()"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7K1fwJYRwaG"
      },
      "source": [
        "# df_train['prev_argument'] = df_train.apply(lambda row: eval(row.context)[-1], axis=1)\n",
        "# df_test['prev_argument'] = df_test.apply(lambda row: eval(row.context)[-1], axis=1)\n",
        "# df_valid['prev_argument'] = df_valid.apply(lambda row: eval(row.context)[-1], axis=1)\n",
        "\n",
        "df_train['context'] = df_train.apply(lambda row: ' '.join(eval(row.context)), axis=1)\n",
        "df_test['context'] = df_test.apply(lambda row: ' '.join(eval(row.context)), axis=1)\n",
        "# df_valid['context'] = df_valid.apply(lambda row: ' '.join(eval(row.context)), axis=1)\n",
        "\n",
        "df_test['text'] = df_test.apply(lambda row: eval(row.text)[0], axis=1)"
      ],
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0NLhsawuwN2"
      },
      "source": [
        "# df_train['cleaned_text'] = df_train['text'].map(lambda x: cleanData(x))\n",
        "# df_test['cleaned_text'] = df_test['text'].map(lambda x: cleanData(x))\n",
        "# df_valid['cleaned_text'] = df_valid['text'].map(lambda x: cleanData(x))\n",
        "\n",
        "# df_train['cleaned_context'] = df_train['context'].map(lambda x: cleanData(x))\n",
        "# df_test['cleaned_context'] = df_test['context'].map(lambda x: cleanData(x))\n",
        "# df_valid['cleaned_context'] = df_valid['context'].map(lambda x: cleanData(x))\n",
        "\n",
        "# df_train['cleaned_prev_argument'] = df_train['prev_argument'].map(lambda x: cleanData(x))\n",
        "# df_test['cleaned_prev_argument'] = df_test['prev_argument'].map(lambda x: cleanData(x))\n",
        "# df_valid['cleaned_prev_argument'] = df_valid['prev_argument'].map(lambda x: cleanData(x))"
      ],
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRC1wHp4wP69"
      },
      "source": [
        "# def train_word2vec(df):\n",
        "\n",
        "#     texts = (df[\"cleaned_context\"] + df[\"cleaned_text\"]).to_numpy().tolist()\n",
        "\n",
        "#     tok_texts = [word_tokenize(text) for text in texts]\n",
        "\n",
        "#     return Word2Vec(tok_texts, sg=1, size=100, window=10, min_count=5, workers=4,\n",
        "#                     iter=100)"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YhzTctRvkx_"
      },
      "source": [
        "# train_w2v_model = train_word2vec(df_train)\n",
        "# test_w2v_model = train_word2vec(df_test)\n",
        "# valid_w2v_model = train_word2vec(df_valid)"
      ],
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaS-IYJ-w4yu"
      },
      "source": [
        "# train_w2v_model.save('drive/My Drive/UST/6000H/ml4nlp-argimpact/train_w2v.model')\n",
        "# test_w2v_model.save('drive/My Drive/UST/6000H/ml4nlp-argimpact/test_w2v.model')\n",
        "# valid_w2v_model.save('drive/My Drive/UST/6000H/ml4nlp-argimpact/valid_w2v.model')"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfmzeP9948kr"
      },
      "source": [
        "# train_w2v_model = Sentence2Vec('drive/My Drive/UST/6000H/ml4nlp-argimpact/train_w2v.model')\n",
        "# test_w2v_model = Sentence2Vec('drive/My Drive/UST/6000H/ml4nlp-argimpact/test_w2v.model')\n",
        "# valid_w2v_model = Sentence2Vec('drive/My Drive/UST/6000H/ml4nlp-argimpact/valid_w2v.model')"
      ],
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMtQkyNc5KU6"
      },
      "source": [
        "# df_train[\"s2v_similarity\"] = df_train.apply(lambda row: train_w2v_model.similarity(row.cleaned_text, row.cleaned_prev_argument), axis=1)"
      ],
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsE-kBjN5oJN"
      },
      "source": [
        "# df_train.groupby(by='impact_label').mean()"
      ],
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHsadZnvcDM8"
      },
      "source": [
        "df_train['impact_label'] = df_train.impact_label.map({\"NOT_IMPACTFUL\": 0, \"MEDIUM_IMPACT\": 1, \"IMPACTFUL\": 2})\n",
        "# df_valid['impact_label'] = df_valid.impact_label.map({\"NOT_IMPACTFUL\": 0, \"MEDIUM_IMPACT\": 1, \"IMPACTFUL\": 2})"
      ],
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuC1fwGF62bB"
      },
      "source": [
        "df_train['cleaned_stance_label'] = df_train['stance_label'].apply(lambda x: ' '.join(eval(x)[1:]))\n",
        "df_test['cleaned_stance_label'] = df_test['stance_label'].apply(lambda x: ' '.join(eval(x)[1:]))\n",
        "# df_valid['cleaned_stance_label'] = df_valid['stance_label'].apply(lambda x: ' '.join(eval(x)[1:]))"
      ],
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zebwi3jvd8Wb"
      },
      "source": [
        "# df_train['previous_argument_type'] = df_train['stance_label'].apply(lambda x: eval(x)[-1])\n",
        "# df_test['previous_argument_type'] = df_test['stance_label'].apply(lambda x: eval(x)[-1])\n",
        "# df_valid['previous_argument_type'] = df_valid['stance_label'].apply(lambda x: eval(x)[-1])"
      ],
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nO-2WlleADV"
      },
      "source": [
        "# df_train['previous_argument_type'] = df_train.previous_argument_type.map({\"OPPOSE\": 0, \"SUPPORT\": 1})\n",
        "# df_test['previous_argument_type'] = df_test.previous_argument_type.map({\"OPPOSE\": 0, \"SUPPORT\": 1})\n",
        "# df_valid['previous_argument_type'] = df_valid.previous_argument_type.map({\"OPPOSE\": 0, \"SUPPORT\": 1})"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Meg3SKu_Vm7A"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import metrics"
      ],
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTXMtM7KSy2D"
      },
      "source": [
        "text_count_vect = CountVectorizer(lowercase=True, stop_words=\"english\", ngram_range=(1, 4))\n",
        "context_count_vect = CountVectorizer(lowercase=True, stop_words=\"english\", ngram_range=(1, 4))"
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ414Sj37XAO"
      },
      "source": [
        "stance_count_vect = CountVectorizer(lowercase=True, ngram_range=(1, 5))"
      ],
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk9yLvBgS2aW"
      },
      "source": [
        "X_train = count_vect.fit_transform(df_train['text'].to_numpy())\n",
        "# X_valid = count_vect.transform(df_valid['text'].to_numpy())\n",
        "X_test = count_vect.transform(df_test['text'].to_numpy())"
      ],
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlKUEftD8zH8"
      },
      "source": [
        "train_context_count_vect = count_vect.fit_transform(df_train['context'].to_numpy())\n",
        "# valid_context_count_vect = count_vect.transform(df_valid['context'].to_numpy())\n",
        "test_context_count_vect = count_vect.transform(df_test['context'].to_numpy())"
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i64IP4Ie7oS2"
      },
      "source": [
        "train_stance = stance_count_vect.fit_transform(df_train['cleaned_stance_label'].to_numpy())\n",
        "# valid_stance = stance_count_vect.transform(df_valid['cleaned_stance_label'].to_numpy())\n",
        "test_stance = stance_count_vect.transform(df_test['cleaned_stance_label'].to_numpy())"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75YhHljDTMkY"
      },
      "source": [
        "X_train = hstack((X_train, train_context_count_vect))\n",
        "# X_valid = hstack((X_valid, valid_context_count_vect))\n",
        "X_test = hstack((X_test, test_context_count_vect))\n",
        "X_train = hstack((X_train, train_stance))\n",
        "# X_valid = hstack((X_valid, valid_stance))\n",
        "X_test = hstack((X_test, test_stance))"
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3InW9ByTe6m"
      },
      "source": [
        "y_train = df_train['impact_label'].to_numpy()\n",
        "# y_valid = df_valid['impact_label'].to_numpy()"
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUJqXZP4TRQB"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9CjktaUpvI_"
      },
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [100, 200, 500]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [5, 8, 10, 20, 30]\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Create the random grid\n",
        "param_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf}"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo0TSHNJTU7f"
      },
      "source": [
        "sgd = SGDClassifier()\n",
        "rfc = RandomForestClassifier()"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXWyvqGbT7GE"
      },
      "source": [
        "# gs = GridSearchCV(rfc, param_grid=param_grid, verbose=1)"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJs6QARRp5ht",
        "outputId": "238d1763-4f85-432f-9b57-cb2200461da0"
      },
      "source": [
        "sgd.fit(X_train, y_train)\n",
        "# rfc.fit(X_train, y_train)"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
              "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
              "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qARjFJrrHxp",
        "outputId": "f9a4894f-231a-44f4-cd46-7aba9231214f"
      },
      "source": [
        "validation_pred = sgd.predict(X_valid)\n",
        "print(f\"SGD F-1 score: {metrics.f1_score(df_valid.impact_label.to_numpy(), validation_pred, average='macro')}\")\n",
        "\n",
        "validation_pred = rfc.predict(X_valid)\n",
        "print(f\"RFC F-1 score: {metrics.f1_score(df_valid.impact_label.to_numpy(), validation_pred, average='macro')}\")"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SGD F-1 score: 0.5452076017456213\n",
            "RFC F-1 score: 0.5089825751531633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9t9mDHZb9fa"
      },
      "source": [
        "# text_clf.fit(df_train.text.to_numpy(), df_train.impact_label.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoLvWUClcIa8"
      },
      "source": [
        "# validation_pred = text_clf.predict(df_valid.text.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34T99Gv4crEg"
      },
      "source": [
        "# print(f\"F-1 score: {metrics.f1_score(df_valid.impact_label.to_numpy(), validation_pred, average='macro')}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQGhHgktcOIW"
      },
      "source": [
        "# metrics.classification_report(df_valid.impact_label.to_numpy(), validation_pred, target_names=class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8cb1C2ES2U9"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NGjO5MHUH7z"
      },
      "source": [
        "parameters = {\n",
        "    'feats__vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
        "    'clf__alpha': (0.02, 0.03, 0.2),\n",
        "}\n",
        "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2LmrFmH4hDi",
        "outputId": "e7af0551-4827-4215-951f-830ed1e10bad"
      },
      "source": [
        "gs_clf.fit(df_train.text.to_numpy(), df_train.impact_label.to_numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   19.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('feats',\n",
              "                                        FeatureUnion(n_jobs=None,\n",
              "                                                     transformer_list=[('vect',\n",
              "                                                                        CountVectorizer(analyzer='word',\n",
              "                                                                                        binary=False,\n",
              "                                                                                        decode_error='strict',\n",
              "                                                                                        dtype=<class 'numpy.int64'>,\n",
              "                                                                                        encoding='utf-8',\n",
              "                                                                                        input='content',\n",
              "                                                                                        lowercase=True,\n",
              "                                                                                        max_df=1.0,\n",
              "                                                                                        max_features=None,\n",
              "                                                                                        min_df=1,\n",
              "                                                                                        ngram_range=(1,\n",
              "                                                                                                     1),\n",
              "                                                                                        preprocessor=None,\n",
              "                                                                                        st...\n",
              "                                                      n_iter_no_change=5,\n",
              "                                                      n_jobs=None, penalty='l2',\n",
              "                                                      power_t=0.5,\n",
              "                                                      random_state=42,\n",
              "                                                      shuffle=True, tol=None,\n",
              "                                                      validation_fraction=0.1,\n",
              "                                                      verbose=0,\n",
              "                                                      warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'clf__alpha': (0.01, 0.001),\n",
              "                         'feats__vect__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 411
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlLkbB454pdL",
        "outputId": "82c9eb2d-3590-46a7-af0a-45607acdcc10"
      },
      "source": [
        "gs_clf.cv_results_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.33352962, 1.07944336, 2.03904166, 0.29629989, 1.03692803,\n",
              "        1.89910464]),\n",
              " 'mean_score_time': array([0.07668324, 0.15674677, 0.21972637, 0.06506205, 0.14441047,\n",
              "        0.1965364 ]),\n",
              " 'mean_test_score': array([0.61257253, 0.61121857, 0.60754352, 0.54158607, 0.5655706 ,\n",
              "        0.59748549]),\n",
              " 'param_clf__alpha': masked_array(data=[0.01, 0.01, 0.01, 0.001, 0.001, 0.001],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_feats__vect__ngram_range': masked_array(data=[(1, 1), (1, 2), (1, 3), (1, 1), (1, 2), (1, 3)],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'clf__alpha': 0.01, 'feats__vect__ngram_range': (1, 1)},\n",
              "  {'clf__alpha': 0.01, 'feats__vect__ngram_range': (1, 2)},\n",
              "  {'clf__alpha': 0.01, 'feats__vect__ngram_range': (1, 3)},\n",
              "  {'clf__alpha': 0.001, 'feats__vect__ngram_range': (1, 1)},\n",
              "  {'clf__alpha': 0.001, 'feats__vect__ngram_range': (1, 2)},\n",
              "  {'clf__alpha': 0.001, 'feats__vect__ngram_range': (1, 3)}],\n",
              " 'rank_test_score': array([1, 2, 3, 6, 5, 4], dtype=int32),\n",
              " 'split0_test_score': array([0.61218569, 0.60444874, 0.60638298, 0.5696325 , 0.57059961,\n",
              "        0.57350097]),\n",
              " 'split1_test_score': array([0.62765957, 0.62765957, 0.61798839, 0.54352031, 0.56092843,\n",
              "        0.62185687]),\n",
              " 'split2_test_score': array([0.61992263, 0.62282398, 0.61121857, 0.53384913, 0.56769826,\n",
              "        0.61218569]),\n",
              " 'split3_test_score': array([0.59381044, 0.59477756, 0.59574468, 0.55319149, 0.56479691,\n",
              "        0.60831721]),\n",
              " 'split4_test_score': array([0.60928433, 0.60638298, 0.60638298, 0.50773694, 0.56382979,\n",
              "        0.57156673]),\n",
              " 'std_fit_time': array([0.00472693, 0.02033829, 0.06274503, 0.01625531, 0.02685177,\n",
              "        0.14986623]),\n",
              " 'std_score_time': array([0.0064748 , 0.01265603, 0.01239852, 0.00676494, 0.01304271,\n",
              "        0.03374085]),\n",
              " 'std_test_score': array([0.01135448, 0.01220256, 0.00727334, 0.02064293, 0.00331652,\n",
              "        0.0208539 ])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 412
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t5m1Dmy40Fd"
      },
      "source": [
        "validation_pred = gs_clf.predict(df_valid.text.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHBNBDE-43sx",
        "outputId": "5066585f-ba0c-41e8-965b-6ff8743d55ed"
      },
      "source": [
        "print(f\"F-1 score: {metrics.f1_score(df_valid.impact_label.to_numpy(), validation_pred, average='macro')}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-1 score: 0.4852736607231976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utWsjzCtUQvZ",
        "outputId": "77c68ee5-e58d-4fae-c1ba-61ca330e6876"
      },
      "source": [
        "gs_clf.fit(df_train.text.to_numpy(), df_train.impact_label.to_numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   24.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('feats',\n",
              "                                        FeatureUnion(n_jobs=None,\n",
              "                                                     transformer_list=[('vect',\n",
              "                                                                        CountVectorizer(analyzer='word',\n",
              "                                                                                        binary=False,\n",
              "                                                                                        decode_error='strict',\n",
              "                                                                                        dtype=<class 'numpy.int64'>,\n",
              "                                                                                        encoding='utf-8',\n",
              "                                                                                        input='content',\n",
              "                                                                                        lowercase=True,\n",
              "                                                                                        max_df=1.0,\n",
              "                                                                                        max_features=None,\n",
              "                                                                                        min_df=1,\n",
              "                                                                                        ngram_range=(1,\n",
              "                                                                                                     1),\n",
              "                                                                                        preprocessor=None,\n",
              "                                                                                        st...\n",
              "                                                      n_iter_no_change=5,\n",
              "                                                      n_jobs=None, penalty='l2',\n",
              "                                                      power_t=0.5,\n",
              "                                                      random_state=42,\n",
              "                                                      shuffle=True, tol=None,\n",
              "                                                      validation_fraction=0.1,\n",
              "                                                      verbose=0,\n",
              "                                                      warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'clf__alpha': (0.01, 0.001),\n",
              "                         'feats__vect__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 383
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiR5Sv_AZKD5",
        "outputId": "6cae0c3c-d045-4dab-df24-382b54e68dd7"
      },
      "source": [
        "gs_clf.cv_results_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.40860076, 1.26529689, 2.40461206, 0.36888561, 1.25734696,\n",
              "        2.24724402]),\n",
              " 'mean_score_time': array([0.09286661, 0.17571011, 0.27506499, 0.08236485, 0.17906299,\n",
              "        0.25027771]),\n",
              " 'mean_test_score': array([0.6153257 , 0.62280889, 0.62185424, 0.55033433, 0.60178851,\n",
              "        0.60895539]),\n",
              " 'param_clf__alpha': masked_array(data=[0.01, 0.01, 0.01, 0.001, 0.001, 0.001],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_feats__vect__ngram_range': masked_array(data=[(1, 1), (1, 2), (1, 3), (1, 1), (1, 2), (1, 3)],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'clf__alpha': 0.01, 'feats__vect__ngram_range': (1, 1)},\n",
              "  {'clf__alpha': 0.01, 'feats__vect__ngram_range': (1, 2)},\n",
              "  {'clf__alpha': 0.01, 'feats__vect__ngram_range': (1, 3)},\n",
              "  {'clf__alpha': 0.001, 'feats__vect__ngram_range': (1, 1)},\n",
              "  {'clf__alpha': 0.001, 'feats__vect__ngram_range': (1, 2)},\n",
              "  {'clf__alpha': 0.001, 'feats__vect__ngram_range': (1, 3)}],\n",
              " 'rank_test_score': array([3, 1, 2, 6, 5, 4], dtype=int32),\n",
              " 'split0_test_score': array([0.61703822, 0.61863057, 0.62420382, 0.53105096, 0.60589172,\n",
              "        0.60350318]),\n",
              " 'split1_test_score': array([0.61863057, 0.64012739, 0.63455414, 0.53742038, 0.59235669,\n",
              "        0.60509554]),\n",
              " 'split2_test_score': array([0.5955414 , 0.61544586, 0.60589172, 0.58359873, 0.57882166,\n",
              "        0.59633758]),\n",
              " 'split3_test_score': array([0.62231076, 0.61354582, 0.62310757, 0.51633466, 0.61195219,\n",
              "        0.62071713]),\n",
              " 'split4_test_score': array([0.62310757, 0.62629482, 0.62151394, 0.58326693, 0.61992032,\n",
              "        0.61912351]),\n",
              " 'std_fit_time': array([0.01193741, 0.02193734, 0.04619364, 0.02147105, 0.011583  ,\n",
              "        0.15248341]),\n",
              " 'std_score_time': array([0.00392539, 0.01137116, 0.01431437, 0.01085759, 0.01327753,\n",
              "        0.0366504 ]),\n",
              " 'std_test_score': array([0.01014517, 0.00969081, 0.00920105, 0.02787713, 0.01459681,\n",
              "        0.00943995])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 384
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idiuoNrjVh_I"
      },
      "source": [
        "predictions = sgd.predict(X_test)"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18_AZI4PWVc4"
      },
      "source": [
        "submission = df_test[['id']]"
      ],
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhVe4MAFYBXh",
        "outputId": "fa4c307f-7681-4cd1-8c3f-5a6bbc04d952"
      },
      "source": [
        "submission['pred'] = predictions"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vOuwptsYC7d"
      },
      "source": [
        "submission.to_csv('drive/My Drive/UST/6000H/sgd.csv', index=False)"
      ],
      "execution_count": 302,
      "outputs": []
    }
  ]
}