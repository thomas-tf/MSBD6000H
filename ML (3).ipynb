{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKavJMuwJu7i",
        "outputId": "222bf974-c158-4fde-f381-7e5e696f2030"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1441,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrI-CjZtLVbM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb81b3b-09f3-44a2-dd3c-65a4cc37cbef"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from gensim.models import Word2Vec\n",
        "from nltk import word_tokenize\n",
        "from scipy.sparse import hstack\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1442,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1442
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uec56EL3LFTh"
      },
      "source": [
        "df_train = pd.read_csv(\"drive/My Drive/UST/6000H/ml4nlp-argimpact/train.csv\")\n",
        "df_test = pd.read_csv(\"drive/My Drive/UST/6000H/ml4nlp-argimpact/test.csv\")\n",
        "df_valid = pd.read_csv(\"drive/My Drive/UST/6000H/ml4nlp-argimpact/valid.csv\")"
      ],
      "execution_count": 1443,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFssvBvwLLSH"
      },
      "source": [
        "# df_train = df_train.append(df_valid)"
      ],
      "execution_count": 1444,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PULuW2kQL0e_"
      },
      "source": [
        "class_names = df_train.impact_label.unique().tolist()"
      ],
      "execution_count": 1445,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7K1fwJYRwaG"
      },
      "source": [
        "df_train['context'] = df_train.apply(lambda row: ' '.join(eval(row.context)), axis=1)\n",
        "df_test['context'] = df_test.apply(lambda row: ' '.join(eval(row.context)), axis=1)\n",
        "df_valid['context'] = df_valid.apply(lambda row: ' '.join(eval(row.context)), axis=1)\n",
        "\n",
        "df_test['text'] = df_test.apply(lambda row: eval(row.text)[0], axis=1)"
      ],
      "execution_count": 1446,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHsadZnvcDM8"
      },
      "source": [
        "df_train['impact_label'] = df_train.impact_label.map({\"NOT_IMPACTFUL\": 0, \"MEDIUM_IMPACT\": 1, \"IMPACTFUL\": 2})\n",
        "df_valid['impact_label'] = df_valid.impact_label.map({\"NOT_IMPACTFUL\": 0, \"MEDIUM_IMPACT\": 1, \"IMPACTFUL\": 2})"
      ],
      "execution_count": 1447,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuC1fwGF62bB"
      },
      "source": [
        "df_train['cleaned_stance_label'] = df_train['stance_label'].apply(lambda x: ' '.join(eval(x)[1:]))\n",
        "df_test['cleaned_stance_label'] = df_test['stance_label'].apply(lambda x: ' '.join(eval(x)[1:]))\n",
        "df_valid['cleaned_stance_label'] = df_valid['stance_label'].apply(lambda x: ' '.join(eval(x)[1:]))"
      ],
      "execution_count": 1448,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1hf0NRicLs7"
      },
      "source": [
        "df_train[\"text\"] = df_train[\"context\"] + \" \" + df_train[\"text\"]\n",
        "df_test[\"text\"] = df_test[\"context\"] + \" \" + df_test[\"text\"]\n",
        "df_valid[\"text\"] = df_valid[\"context\"] + \" \" + df_valid[\"text\"]"
      ],
      "execution_count": 1449,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Meg3SKu_Vm7A"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1450,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTXMtM7KSy2D"
      },
      "source": [
        "text_count_vect = CountVectorizer(lowercase=True, stop_words=\"english\", ngram_range=(1, 4), min_df=0.005)\n",
        "# context_count_vect = CountVectorizer(lowercase=True, stop_words=\"english\", ngram_range=(1, 5))\n",
        "stance_count_vect = CountVectorizer(lowercase=True, ngram_range=(1, 5))"
      ],
      "execution_count": 1451,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk9yLvBgS2aW"
      },
      "source": [
        "X_train = text_count_vect.fit_transform(df_train['text'].to_numpy())\n",
        "X_valid = text_count_vect.transform(df_valid['text'].to_numpy())\n",
        "# X_test = text_count_vect.transform(df_test['text'].to_numpy())"
      ],
      "execution_count": 1452,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlKUEftD8zH8"
      },
      "source": [
        "# train_context_count_vect = context_count_vect.fit_transform(df_train['context'].to_numpy())\n",
        "# valid_context_count_vect = context_count_vect.transform(df_valid['context'].to_numpy())\n",
        "# test_context_count_vect = context_count_vect.transform(df_test['context'].to_numpy())"
      ],
      "execution_count": 1453,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i64IP4Ie7oS2"
      },
      "source": [
        "train_stance = stance_count_vect.fit_transform(df_train['cleaned_stance_label'].to_numpy())\n",
        "valid_stance = stance_count_vect.transform(df_valid['cleaned_stance_label'].to_numpy())\n",
        "# test_stance = stance_count_vect.transform(df_test['cleaned_stance_label'].to_numpy())"
      ],
      "execution_count": 1454,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md3BaX_JECzJ"
      },
      "source": [
        "tfidf_text = TfidfVectorizer(max_features = 10000, ngram_range=(1,4))\n",
        "# tfidf_context = TfidfVectorizer(max_features = 10000, ngram_range=(1,4))"
      ],
      "execution_count": 1455,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thhq4w1QCeBh"
      },
      "source": [
        "train_text_tfidf_vect = tfidf_text.fit_transform(df_train['text'].to_numpy())\n",
        "valid_text_tfidf_vect = tfidf_text.transform(df_valid['text'].to_numpy())"
      ],
      "execution_count": 1456,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfmBSynbEG2M"
      },
      "source": [
        "# train_context_tfidf_vect = tfidf_context.fit_transform(df_train['context'].to_numpy())\n",
        "# valid_context_tfidf_vect = tfidf_context.transform(df_valid['context'].to_numpy())"
      ],
      "execution_count": 1457,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75YhHljDTMkY"
      },
      "source": [
        "# X_train = hstack((X_train, train_context_count_vect))\n",
        "# X_valid = hstack((X_valid, valid_context_count_vect))\n",
        "# # X_test = hstack((X_test, test_context_count_vect))\n",
        "\n",
        "X_train = hstack((X_train, train_stance))\n",
        "X_valid = hstack((X_valid, valid_stance))\n",
        "# X_test = hstack((X_test, test_stance))\n",
        "\n",
        "# X_train = hstack((X_train, train_text_tfidf_vect))\n",
        "# X_valid = hstack((X_valid, valid_text_tfidf_vect))\n",
        "\n",
        "# X_train = hstack((X_train, train_context_tfidf_vect))\n",
        "# X_valid = hstack((X_valid, valid_context_tfidf_vect))"
      ],
      "execution_count": 1458,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUFCyzG5JJ9g"
      },
      "source": [
        "y_train = df_train.impact_label.to_numpy()\n",
        "y_valid = df_valid.impact_label.to_numpy()"
      ],
      "execution_count": 1459,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo0TSHNJTU7f"
      },
      "source": [
        "sgd = SGDClassifier(random_state=42)\n",
        "rfc = RandomForestClassifier(random_state=42)"
      ],
      "execution_count": 1460,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJs6QARRp5ht",
        "outputId": "9235e232-f8aa-4836-9d0d-a21ebb5b8290"
      },
      "source": [
        "sgd.fit(X_train, y_train)"
      ],
      "execution_count": 1461,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
              "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
              "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1461
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iBfVlWuNjCO",
        "outputId": "b3002fec-f785-40fe-c99c-ad51afba2c94"
      },
      "source": [
        "rfc.fit(X_train, y_train)"
      ],
      "execution_count": 1462,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1462
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qARjFJrrHxp",
        "outputId": "561a90cc-4cff-43f7-c66a-91405ca88e65"
      },
      "source": [
        "validation_pred = sgd.predict(X_valid)\n",
        "print(f\"SGD F-1 score: {metrics.f1_score(df_valid.impact_label.to_numpy(), validation_pred, average='macro')}\")\n",
        "\n",
        "validation_pred = rfc.predict(X_valid)\n",
        "print(f\"RF F-1 score: {metrics.f1_score(df_valid.impact_label.to_numpy(), validation_pred, average='macro')}\")"
      ],
      "execution_count": 1463,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SGD F-1 score: 0.5365381634422253\n",
            "RF F-1 score: 0.6014260746366586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9t9mDHZb9fa"
      },
      "source": [
        "# text_clf.fit(df_train.text.to_numpy(), df_train.impact_label.to_numpy())"
      ],
      "execution_count": 1401,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoLvWUClcIa8"
      },
      "source": [
        "# validation_pred = text_clf.predict(df_valid.text.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34T99Gv4crEg"
      },
      "source": [
        "# print(f\"F-1 score: {metrics.f1_score(df_valid.impact_label.to_numpy(), validation_pred, average='macro')}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQGhHgktcOIW"
      },
      "source": [
        "# metrics.classification_report(df_valid.impact_label.to_numpy(), validation_pred, target_names=class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8cb1C2ES2U9"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NGjO5MHUH7z"
      },
      "source": [
        "parameters = {\n",
        "    'feats__vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
        "    'clf__alpha': (0.02, 0.03, 0.2),\n",
        "}\n",
        "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2LmrFmH4hDi",
        "outputId": "e7af0551-4827-4215-951f-830ed1e10bad"
      },
      "source": [
        "gs_clf.fit(df_train.text.to_numpy(), df_train.impact_label.to_numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   19.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('feats',\n",
              "                                        FeatureUnion(n_jobs=None,\n",
              "                                                     transformer_list=[('vect',\n",
              "                                                                        CountVectorizer(analyzer='word',\n",
              "                                                                                        binary=False,\n",
              "                                                                                        decode_error='strict',\n",
              "                                                                                        dtype=<class 'numpy.int64'>,\n",
              "                                                                                        encoding='utf-8',\n",
              "                                                                                        input='content',\n",
              "                                                                                        lowercase=True,\n",
              "                                                                                        max_df=1.0,\n",
              "                                                                                        max_features=None,\n",
              "                                                                                        min_df=1,\n",
              "                                                                                        ngram_range=(1,\n",
              "                                                                                                     1),\n",
              "                                                                                        preprocessor=None,\n",
              "                                                                                        st...\n",
              "                                                      n_iter_no_change=5,\n",
              "                                                      n_jobs=None, penalty='l2',\n",
              "                                                      power_t=0.5,\n",
              "                                                      random_state=42,\n",
              "                                                      shuffle=True, tol=None,\n",
              "                                                      validation_fraction=0.1,\n",
              "                                                      verbose=0,\n",
              "                                                      warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'clf__alpha': (0.01, 0.001),\n",
              "                         'feats__vect__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 411
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlLkbB454pdL",
        "outputId": "82c9eb2d-3590-46a7-af0a-45607acdcc10"
      },
      "source": [
        "gs_clf.cv_results_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.33352962, 1.07944336, 2.03904166, 0.29629989, 1.03692803,\n",
              "        1.89910464]),\n",
              " 'mean_score_time': array([0.07668324, 0.15674677, 0.21972637, 0.06506205, 0.14441047,\n",
              "        0.1965364 ]),\n",
              " 'mean_test_score': array([0.61257253, 0.61121857, 0.60754352, 0.54158607, 0.5655706 ,\n",
              "        0.59748549]),\n",
              " 'param_clf__alpha': masked_array(data=[0.01, 0.01, 0.01, 0.001, 0.001, 0.001],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_feats__vect__ngram_range': masked_array(data=[(1, 1), (1, 2), (1, 3), (1, 1), (1, 2), (1, 3)],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'clf__alpha': 0.01, 'feats__vect__ngram_range': (1, 1)},\n",
              "  {'clf__alpha': 0.01, 'feats__vect__ngram_range': (1, 2)},\n",
              "  {'clf__alpha': 0.01, 'feats__vect__ngram_range': (1, 3)},\n",
              "  {'clf__alpha': 0.001, 'feats__vect__ngram_range': (1, 1)},\n",
              "  {'clf__alpha': 0.001, 'feats__vect__ngram_range': (1, 2)},\n",
              "  {'clf__alpha': 0.001, 'feats__vect__ngram_range': (1, 3)}],\n",
              " 'rank_test_score': array([1, 2, 3, 6, 5, 4], dtype=int32),\n",
              " 'split0_test_score': array([0.61218569, 0.60444874, 0.60638298, 0.5696325 , 0.57059961,\n",
              "        0.57350097]),\n",
              " 'split1_test_score': array([0.62765957, 0.62765957, 0.61798839, 0.54352031, 0.56092843,\n",
              "        0.62185687]),\n",
              " 'split2_test_score': array([0.61992263, 0.62282398, 0.61121857, 0.53384913, 0.56769826,\n",
              "        0.61218569]),\n",
              " 'split3_test_score': array([0.59381044, 0.59477756, 0.59574468, 0.55319149, 0.56479691,\n",
              "        0.60831721]),\n",
              " 'split4_test_score': array([0.60928433, 0.60638298, 0.60638298, 0.50773694, 0.56382979,\n",
              "        0.57156673]),\n",
              " 'std_fit_time': array([0.00472693, 0.02033829, 0.06274503, 0.01625531, 0.02685177,\n",
              "        0.14986623]),\n",
              " 'std_score_time': array([0.0064748 , 0.01265603, 0.01239852, 0.00676494, 0.01304271,\n",
              "        0.03374085]),\n",
              " 'std_test_score': array([0.01135448, 0.01220256, 0.00727334, 0.02064293, 0.00331652,\n",
              "        0.0208539 ])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 412
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t5m1Dmy40Fd"
      },
      "source": [
        "validation_pred = gs_clf.predict(df_valid.text.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHBNBDE-43sx",
        "outputId": "5066585f-ba0c-41e8-965b-6ff8743d55ed"
      },
      "source": [
        "print(f\"F-1 score: {metrics.f1_score(df_valid.impact_label.to_numpy(), validation_pred, average='macro')}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F-1 score: 0.4852736607231976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utWsjzCtUQvZ",
        "outputId": "77c68ee5-e58d-4fae-c1ba-61ca330e6876"
      },
      "source": [
        "gs_clf.fit(df_train.text.to_numpy(), df_train.impact_label.to_numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   24.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('feats',\n",
              "                                        FeatureUnion(n_jobs=None,\n",
              "                                                     transformer_list=[('vect',\n",
              "                                                                        CountVectorizer(analyzer='word',\n",
              "                                                                                        binary=False,\n",
              "                                                                                        decode_error='strict',\n",
              "                                                                                        dtype=<class 'numpy.int64'>,\n",
              "                                                                                        encoding='utf-8',\n",
              "                                                                                        input='content',\n",
              "                                                                                        lowercase=True,\n",
              "                                                                                        max_df=1.0,\n",
              "                                                                                        max_features=None,\n",
              "                                                                                        min_df=1,\n",
              "                                                                                        ngram_range=(1,\n",
              "                                                                                                     1),\n",
              "                                                                                        preprocessor=None,\n",
              "                                                                                        st...\n",
              "                                                      n_iter_no_change=5,\n",
              "                                                      n_jobs=None, penalty='l2',\n",
              "                                                      power_t=0.5,\n",
              "                                                      random_state=42,\n",
              "                                                      shuffle=True, tol=None,\n",
              "                                                      validation_fraction=0.1,\n",
              "                                                      verbose=0,\n",
              "                                                      warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'clf__alpha': (0.01, 0.001),\n",
              "                         'feats__vect__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 383
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiR5Sv_AZKD5",
        "outputId": "6cae0c3c-d045-4dab-df24-382b54e68dd7"
      },
      "source": [
        "gs_clf.cv_results_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.40860076, 1.26529689, 2.40461206, 0.36888561, 1.25734696,\n",
              "        2.24724402]),\n",
              " 'mean_score_time': array([0.09286661, 0.17571011, 0.27506499, 0.08236485, 0.17906299,\n",
              "        0.25027771]),\n",
              " 'mean_test_score': array([0.6153257 , 0.62280889, 0.62185424, 0.55033433, 0.60178851,\n",
              "        0.60895539]),\n",
              " 'param_clf__alpha': masked_array(data=[0.01, 0.01, 0.01, 0.001, 0.001, 0.001],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_feats__vect__ngram_range': masked_array(data=[(1, 1), (1, 2), (1, 3), (1, 1), (1, 2), (1, 3)],\n",
              "              mask=[False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'clf__alpha': 0.01, 'feats__vect__ngram_range': (1, 1)},\n",
              "  {'clf__alpha': 0.01, 'feats__vect__ngram_range': (1, 2)},\n",
              "  {'clf__alpha': 0.01, 'feats__vect__ngram_range': (1, 3)},\n",
              "  {'clf__alpha': 0.001, 'feats__vect__ngram_range': (1, 1)},\n",
              "  {'clf__alpha': 0.001, 'feats__vect__ngram_range': (1, 2)},\n",
              "  {'clf__alpha': 0.001, 'feats__vect__ngram_range': (1, 3)}],\n",
              " 'rank_test_score': array([3, 1, 2, 6, 5, 4], dtype=int32),\n",
              " 'split0_test_score': array([0.61703822, 0.61863057, 0.62420382, 0.53105096, 0.60589172,\n",
              "        0.60350318]),\n",
              " 'split1_test_score': array([0.61863057, 0.64012739, 0.63455414, 0.53742038, 0.59235669,\n",
              "        0.60509554]),\n",
              " 'split2_test_score': array([0.5955414 , 0.61544586, 0.60589172, 0.58359873, 0.57882166,\n",
              "        0.59633758]),\n",
              " 'split3_test_score': array([0.62231076, 0.61354582, 0.62310757, 0.51633466, 0.61195219,\n",
              "        0.62071713]),\n",
              " 'split4_test_score': array([0.62310757, 0.62629482, 0.62151394, 0.58326693, 0.61992032,\n",
              "        0.61912351]),\n",
              " 'std_fit_time': array([0.01193741, 0.02193734, 0.04619364, 0.02147105, 0.011583  ,\n",
              "        0.15248341]),\n",
              " 'std_score_time': array([0.00392539, 0.01137116, 0.01431437, 0.01085759, 0.01327753,\n",
              "        0.0366504 ]),\n",
              " 'std_test_score': array([0.01014517, 0.00969081, 0.00920105, 0.02787713, 0.01459681,\n",
              "        0.00943995])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 384
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idiuoNrjVh_I"
      },
      "source": [
        "predictions = sgd.predict(X_test)"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18_AZI4PWVc4"
      },
      "source": [
        "submission = df_test[['id']]"
      ],
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhVe4MAFYBXh",
        "outputId": "fa4c307f-7681-4cd1-8c3f-5a6bbc04d952"
      },
      "source": [
        "submission['pred'] = predictions"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vOuwptsYC7d"
      },
      "source": [
        "submission.to_csv('drive/My Drive/UST/6000H/sgd.csv', index=False)"
      ],
      "execution_count": 302,
      "outputs": []
    }
  ]
}